{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe10eac-3e92-4d1f-afc8-3fcc3d77585e",
   "metadata": {},
   "source": [
    "# MLOps with AKS\n",
    "\n",
    "<b>Objective</b>\n",
    "\n",
    "\n",
    "1. To create a simple model to predict the category for IRIS dataset.\n",
    "2. To use Azure's capability to find the following:\n",
    " - Use dataset drifter to identiy whether there is a drift in the dataset.\n",
    " - If there is a drift then create an automatic email alert for the same.\n",
    " - Model profiling to get an approximation of the resources that might be required for our model.\n",
    " - Deploy the model on AKS with the above profiling values.\n",
    " - Use multiple versions of the best model to introduce AB testing kind of scenarios.\n",
    " - Monitoring using log analytics and application insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ca8d5-31fb-4a5a-9b23-d72df794bce5",
   "metadata": {},
   "source": [
    "## Part - I\n",
    "\n",
    "1. Download the IRIS dataset from the web.\n",
    "2. Convert the labels to numeric representations.\n",
    "3. Push the cleaned dataset to a new folder.\n",
    "4. Upload it to the default datastore of ML workspace.\n",
    "5. Register the dataset.\n",
    "6. Access the dataset to check everything is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aae1a0d-d46e-4dd7-9ca7-c324ebc3a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./dataset\n",
    "!mkdir ./dataset/inputs\n",
    "!mkdir ./dataset/processed_data\n",
    "!mkdir ./dataset/profile-data\n",
    "!mkdir ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9bce475-e373-4133-86c3-76b707c5edae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-09-09 03:43:41--  https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3975 (3.9K) [text/plain]\n",
      "Saving to: ‘./dataset/inputs/iris_raw.csv’\n",
      "\n",
      "./dataset/inputs/ir 100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-09-09 03:43:42 (22.7 MB/s) - ‘./dataset/inputs/iris_raw.csv’ saved [3975/3975]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O ./dataset/inputs/iris_raw.csv https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bac3b28-b338-4c9d-b65b-7ec083fd893f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0\n",
       "5           5.4          3.9           1.7          0.4        0\n",
       "6           4.6          3.4           1.4          0.3        0\n",
       "7           5.0          3.4           1.5          0.2        0\n",
       "8           4.4          2.9           1.4          0.2        0\n",
       "9           4.9          3.1           1.5          0.1        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "raw_data = pd.read_csv('./dataset/inputs/iris_raw.csv') #The shape of the data is (150,5) 4 features + 1 label\n",
    "i2l = dict(enumerate(raw_data.variety.unique().tolist()))\n",
    "l2i = {k:i for i, k in i2l.items()}\n",
    "raw_data.variety = raw_data.variety.map(lambda x : l2i[x])\n",
    "\n",
    "display(raw_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a7d7d7-d757-4f45-a3e5-f018c8250a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.to_csv('./dataset/processed_data/iris_data_base.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057bc585-b152-437f-9834-e31f42af694a",
   "metadata": {},
   "source": [
    "#(or)\n",
    "\"\"\"\n",
    "with open('./auth/azure_details.txt', 'r') as f:\n",
    "    vals = f.readlines()\n",
    "\n",
    "subscription_id = vals[0].strip('\\n')\n",
    "resource_group = vals[1].strip('\\n')\n",
    "workspace_name = vals[2] \n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a347ff56-ed80-493b-9b71-4fd461b4a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config() #we are in the same workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4020de50-609d-4467-bbc2-73da5b333368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./dataset/processed_data/iris_data_base.csv\n",
      "Uploaded ./dataset/processed_data/iris_data_base.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_450e4b2a4918441b8aaa14cfe45c6e3a"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "datastore = ws.get_default_datastore() # points to the native Azure ML Storage\n",
    "\n",
    "datastore.upload(src_dir = './dataset/processed_data', target_path = 'iris_data_base')\n",
    "\n",
    "#from azureml.core.datapath import DataPath\n",
    "#Datastore.get(workspace, 'workspaceblobstore')\n",
    "#iris_dataset = Dataset.File.upload_directory('./dataset/inputs/', DataPath(datastore, 'iris-base-data'), pattern = '*.csv') # for files dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca59cbc-7191-4d4a-b42b-1c105331a069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'iris_data_base/iris_data_base.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"8c0e24d8-8344-45dd-a5ca-1029f2011d63\",\n",
       "    \"name\": \"iris_data_base\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"iris-base-dataset\",\n",
       "    \"workspace\": \"Workspace.create(name='sanjeev-mlops', subscription_id='0d1442c1-d386-4505-9abe-0bedfd63701e', resource_group='sanjeev-mlops')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Registering the dataset\n",
    "dataset =  Dataset.Tabular.from_delimited_files(datastore.path('iris_data_base/iris_data_base.csv'))\n",
    "\n",
    "dataset.register(workspace=ws, name='iris_data_base', description='iris-base-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "307568d1-37f0-4a4c-8b5b-41df80ef0d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_data_base 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0\n",
       "5           5.4          3.9           1.7          0.4        0\n",
       "6           4.6          3.4           1.4          0.3        0\n",
       "7           5.0          3.4           1.5          0.2        0\n",
       "8           4.4          2.9           1.4          0.2        0\n",
       "9           4.9          3.1           1.5          0.1        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#retrieving the dataset from registered datasets\n",
    "dataset = Dataset.get_by_name(ws, name='iris_data_base')\n",
    "df = dataset.to_pandas_dataframe()\n",
    "print(dataset.name, dataset.version)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e791dcf-ea82-4db9-8b17-8a4c3a0279e5",
   "metadata": {},
   "source": [
    "## Part - II\n",
    "\n",
    "1. Train a Random forest model\n",
    "2. Train a decision tree model\n",
    "3. Register the above models\n",
    "4. Create a scoring file\n",
    "5. Do model profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fee584c-8e7d-4706-b975-da4c03b80db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "x, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y , random_state = 1, test_size = 0.3, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab3952dc-2acb-4593-a1e7-473090789a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def printMetrics(model, test_data, y_labels):\n",
    "    predicted = model.predict(test_data)\n",
    "    acc = accuracy_score(y_labels, predicted)\n",
    "    f1 = f1_score(y_labels, predicted, average = 'macro')\n",
    "    precision = precision_score(y_labels, predicted, average = 'macro')\n",
    "    recall = recall_score(y_labels, predicted, average = 'macro')\n",
    "    print('Accuracy', acc)\n",
    "    print('F1', f1)\n",
    "    print('Precision', precision)\n",
    "    print('Recall', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77396c2f-8d02-40e8-8764-ed2defdf381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree classifier\n",
      "--------------------\n",
      "Params:\n",
      "Criterion gini\n",
      "Max Depth 4\n",
      "--------------------\n",
      "Accuracy 0.9777777777777777\n",
      "F1 0.9777530589543938\n",
      "Precision 0.9791666666666666\n",
      "Recall 0.9777777777777779\n"
     ]
    }
   ],
   "source": [
    "## Searching the best parameters using the GridSearchCV for RFC and DTC\n",
    "\n",
    "# Decision Tree Classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'criterion' : ('gini', 'entropy'), 'max_depth' : [i for i in range(2, 9)]}\n",
    "dt = DecisionTreeClassifier(random_state = 198)\n",
    "grid_ = GridSearchCV(dt, params, n_jobs = -1)\n",
    "grid_.fit(X_train, y_train)\n",
    "dt_best = DecisionTreeClassifier(criterion = grid_.best_params_['criterion'], max_depth = grid_.best_params_['max_depth'], random_state =\n",
    "                                198)\n",
    "dt_best.fit(X_train, y_train)\n",
    "\n",
    "print('Decision Tree classifier')\n",
    "print('-' * 20)\n",
    "print('Params:')\n",
    "print(\"Criterion\", grid_.best_params_['criterion'])\n",
    "print(\"Max Depth\", grid_.best_params_['max_depth'])\n",
    "print('-' * 20)\n",
    "printMetrics(dt_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33d7d9e4-6ccf-4b91-b51e-2a72164055d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier\n",
      "--------------------\n",
      "Params:\n",
      "N estimators 100\n",
      "Max Depth 3\n",
      "--------------------\n",
      "Accuracy 0.9777777777777777\n",
      "F1 0.9777530589543938\n",
      "Precision 0.9791666666666666\n",
      "Recall 0.9777777777777779\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "\n",
    "params = {'n_estimators' : [i for i in range(100, 200, 10)], 'max_depth' : [i for i in range(2, 9)]}\n",
    "\n",
    "rfc = RandomForestClassifier(random_state = 198)\n",
    "grid_ = GridSearchCV(rfc, params, n_jobs = -1)\n",
    "grid_.fit(X_train, y_train)\n",
    "\n",
    "rfc_best = RandomForestClassifier(n_estimators = grid_.best_params_['n_estimators'], max_depth = grid_.best_params_['max_depth'], random_state =\n",
    "                                198)\n",
    "rfc_best.fit(X_train, y_train)\n",
    "\n",
    "print('Random Forest classifier')\n",
    "print('-' * 20)\n",
    "print('Params:')\n",
    "print(\"N estimators\", grid_.best_params_['n_estimators'])\n",
    "print(\"Max Depth\", grid_.best_params_['max_depth'])\n",
    "print('-' * 20)\n",
    "printMetrics(rfc_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68035a8b-f9f5-47fa-9ebc-eee0e6cae96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The maximum opset needed by this model is only 1.\n",
      "The maximum opset needed by this model is only 9.\n",
      "The maximum opset needed by this model is only 1.\n",
      "The maximum opset needed by this model is only 9.\n"
     ]
    }
   ],
   "source": [
    "#Converting the essentials into onnx format\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "initial_type = [('float_input', FloatTensorType([None, 4]))] #4 represents the number of features\n",
    "\n",
    "onx = convert_sklearn(dt_best, initial_types=initial_type)\n",
    "\n",
    "with open(\"./model/iris_dt.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())\n",
    "\n",
    "onx = convert_sklearn(dt_best, initial_types=initial_type)\n",
    "\n",
    "with open(\"./model/iris_rfc.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "804b2384-4b5c-44ff-a2e6-de55561af503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model iris-predictor-rfc\n",
      "Registering model iris-predictor-dt\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_rfc = Model.register(model_path = './model/iris_rfc.onnx', model_name = 'iris-predictor-rfc', tags = {'model_version' : 1},\n",
    "                     description = 'RFC for classifying IRIS', workspace = ws)\n",
    "model_dt = Model.register(model_path = './model/iris_dt.onnx', model_name = 'iris-predictor-dt', tags = {'model_version' : 1},\n",
    "                      description = 'DT for classifying IRIS', workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985d2e7b-35f6-4537-b1fa-f9a16671dcaa",
   "metadata": {},
   "source": [
    "### Testing model - local inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b3d401-38ae-4c17-b99d-968154e1ac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1], dtype=int64)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-09 03:44:28.115606436 [W:onnxruntime:, execution_frame.cc:806 VerifyOutputSizes] Expected shape from model of {1} does not match actual shape of {2} for output output_label\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "\n",
    "#iris_predictor = Model(ws, 'iris-predictor', version = 1).download(exist_ok=True) #defaulted under ./models/model_name.onnx\n",
    "\n",
    "sess = rt.InferenceSession(\"./model/iris_rfc.onnx\")\n",
    "\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "\n",
    "test_data = np.array([[5.1, 3.5, 1.4, 0.2], [1.1, 2.8, 4.4, 1.2]])\n",
    "\n",
    "preds = sess.run([label_name], {input_name: test_data.astype(np.float32)})\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ba145-b45a-4a25-b455-fdb0c70a5e00",
   "metadata": {},
   "source": [
    "## Deploying the model as a local web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f73642e9-7963-4123-bc15-0f08f07210f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"assetId\": \"azureml://locations/centralindia/workspaces/466eacc5-059a-407f-8aeb-4439774e2354/environments/iris-env/versions/1\",\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"buildContext\": null,\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"iris-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.8.13\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"numpy\",\n",
       "                        \"pandas\",\n",
       "                        \"onnxruntime\",\n",
       "                        \"joblib\",\n",
       "                        \"azureml-core~=1.44.0\",\n",
       "                        \"azureml-monitoring\",\n",
       "                        \"azureml-defaults~=1.44.0\",\n",
       "                        \"Jinja2<3.1\",\n",
       "                        \"scikit-learn==0.22.2.post1\",\n",
       "                        \"inference-schema[numpy-support]\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"project_environment\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Environment\n",
    "\n",
    "env = CondaDependencies.create(pip_packages=[\"numpy\", \"pandas\", \"onnxruntime\", \"joblib\", \"azureml-core\", \"azureml-monitoring\", \"azureml-defaults\", 'Jinja2<3.1', \"scikit-learn==0.22.2.post1\", \"inference-schema\", \"inference-schema[numpy-support]\"])\n",
    "\n",
    "with open('./model/env.yml', 'w') as f:\n",
    "    f.write(env.serialize_to_string())\n",
    "\n",
    "iris_env = Environment.from_conda_specification(name = 'iris-env', file_path = \"./model/env.yml\")\n",
    "    \n",
    "iris_env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a6ed627-3ce7-4669-9aa8-2091666f8e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"./score_v2.py\",\n",
    "                                   environment=iris_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0188c37-9fec-489b-9651-4fc31884523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo service docker start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93b2c5a3-38cb-4bfc-a72d-bdb2c248a427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model iris-predictor-dt:1 to /tmp/azureml_gb14i9if/iris-predictor-dt/1\n",
      "Generating Docker build context.\n",
      "2022/09/09 03:55:04 Downloading source code...\n",
      "2022/09/09 03:55:05 Finished downloading source code\n",
      "2022/09/09 03:55:06 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2022/09/09 03:55:06 Successfully set up Docker network: acb_default_network\n",
      "2022/09/09 03:55:06 Setting up Docker configuration...\n",
      "2022/09/09 03:55:07 Successfully set up Docker configuration\n",
      "2022/09/09 03:55:07 Logging in to registry: 466eacc5059a407f8aeb4439774e2354.azurecr.io\n",
      "2022/09/09 03:55:08 Successfully logged into 466eacc5059a407f8aeb4439774e2354.azurecr.io\n",
      "2022/09/09 03:55:08 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/09/09 03:55:08 Scanning for dependencies...\n",
      "2022/09/09 03:55:08 Successfully scanned dependencies\n",
      "2022/09/09 03:55:08 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "Step 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n",
      "mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6: Pulling from azureml/openmpi4.1.0-ubuntu20.04\n",
      "d7bfe07ed847: Pulling fs layer\n",
      "1a9a51b4af0d: Pulling fs layer\n",
      "9d74d44c539e: Pulling fs layer\n",
      "829bf1798a9e: Pulling fs layer\n",
      "5fe57cb5a06b: Pulling fs layer\n",
      "0b73c9d3e4c7: Pulling fs layer\n",
      "df3a1ae83fc1: Pulling fs layer\n",
      "622a938b5eec: Pulling fs layer\n",
      "9d0e20c4f643: Pulling fs layer\n",
      "e63d29d12ed0: Pulling fs layer\n",
      "829bf1798a9e: Waiting\n",
      "5fe57cb5a06b: Waiting\n",
      "0b73c9d3e4c7: Waiting\n",
      "df3a1ae83fc1: Waiting\n",
      "622a938b5eec: Waiting\n",
      "9d0e20c4f643: Waiting\n",
      "e63d29d12ed0: Waiting\n",
      "9d74d44c539e: Verifying Checksum\n",
      "9d74d44c539e: Download complete\n",
      "d7bfe07ed847: Verifying Checksum\n",
      "d7bfe07ed847: Download complete\n",
      "5fe57cb5a06b: Verifying Checksum\n",
      "5fe57cb5a06b: Download complete\n",
      "829bf1798a9e: Verifying Checksum\n",
      "829bf1798a9e: Download complete\n",
      "df3a1ae83fc1: Verifying Checksum\n",
      "df3a1ae83fc1: Download complete\n",
      "0b73c9d3e4c7: Verifying Checksum\n",
      "0b73c9d3e4c7: Download complete\n",
      "9d0e20c4f643: Verifying Checksum\n",
      "9d0e20c4f643: Download complete\n",
      "622a938b5eec: Verifying Checksum\n",
      "622a938b5eec: Download complete\n",
      "e63d29d12ed0: Verifying Checksum\n",
      "e63d29d12ed0: Download complete\n",
      "1a9a51b4af0d: Verifying Checksum\n",
      "1a9a51b4af0d: Download complete\n",
      "d7bfe07ed847: Pull complete\n",
      "1a9a51b4af0d: Pull complete\n",
      "9d74d44c539e: Pull complete\n",
      "829bf1798a9e: Pull complete\n",
      "5fe57cb5a06b: Pull complete\n",
      "0b73c9d3e4c7: Pull complete\n",
      "df3a1ae83fc1: Pull complete\n",
      "622a938b5eec: Pull complete\n",
      "9d0e20c4f643: Pull complete\n",
      "e63d29d12ed0: Pull complete\n",
      "Digest: sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n",
      " ---> a126cf3d80b0\n",
      "Step 2/21 : USER root\n",
      " ---> Running in 66de911d96b4\n",
      "Removing intermediate container 66de911d96b4\n",
      " ---> 6438a9c8dc8d\n",
      "Step 3/21 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 800f3473d2a1\n",
      "Removing intermediate container 800f3473d2a1\n",
      " ---> 91c8959bbf9c\n",
      "Step 4/21 : WORKDIR /\n",
      " ---> Running in 931f639beddc\n",
      "Removing intermediate container 931f639beddc\n",
      " ---> a74481b312a3\n",
      "Step 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 14d937de8d85\n",
      "Step 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in db72866542b2\n",
      "Removing intermediate container db72866542b2\n",
      " ---> a26ac9609225\n",
      "Step 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 105af33454a8\n",
      "Step 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_1867cd816376033961c66f81bff348cf -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 0e3f5e000e39\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "setuptools-61.2.0    | 1.3 MB    | ########## | 100% \n",
      "xz-5.2.5             | 389 KB    | ########## | 100% \n",
      "_openmp_mutex-5.1    | 20 KB     | ########## | 100% \n",
      "libgcc-ng-11.2.0     | 8.5 MB    | ########## | 100% \n",
      "ca-certificates-2022 | 131 KB    | ########## | 100% \n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    | ########## | 100% \n",
      "wheel-0.37.1         | 31 KB     | ########## | 100% \n",
      "zlib-1.2.12          | 130 KB    | ########## | 100% \n",
      "libgomp-11.2.0       | 560 KB    | ########## | 100% \n",
      "openssl-1.1.1q       | 3.8 MB    | ########## | 100% \n",
      "readline-8.1.2       | 423 KB    | ########## | 100% \n",
      "tk-8.6.12            | 3.3 MB    | ########## | 100% \n",
      "certifi-2022.6.15    | 156 KB    | ########## | 100% \n",
      "libffi-3.3           | 54 KB     | ########## | 100% \n",
      "pip-22.1.2           | 2.9 MB    | ########## | 100% \n",
      "python-3.8.13        | 22.7 MB   | ########## | 100% \n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n",
      "ld_impl_linux-64-2.3 | 732 KB    | ########## | 100% \n",
      "sqlite-3.39.2        | 1.5 MB    | ########## | 100% \n",
      "ncurses-6.3          | 1.1 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Installing pip dependencies: ...working... \n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_1867cd816376033961c66f81bff348cf/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.9eivtxd_.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.23.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.1/17.1 MB 39.0 MB/s eta 0:00:00\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.4.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.7/11.7 MB 28.3 MB/s eta 0:00:00\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.12.1-cp38-cp38-manylinux_2_27_x86_64.whl (4.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 48.5 MB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.0/307.0 kB 48.6 MB/s eta 0:00:00\n",
      "Collecting azureml-core~=1.44.0\n",
      "  Downloading azureml_core-1.44.0-py3-none-any.whl (2.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 52.8 MB/s eta 0:00:00\n",
      "Collecting azureml-monitoring\n",
      "  Downloading azureml-monitoring-0.1.0a21.tar.gz (14.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.6/14.6 MB 43.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting azureml-defaults~=1.44.0\n",
      "  Downloading azureml_defaults-1.44.0-py3-none-any.whl (2.0 kB)\n",
      "Collecting Jinja2<3.1\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.6/133.6 kB 5.1 MB/s eta 0:00:00\n",
      "Collecting scikit-learn==0.22.2.post1\n",
      "  Downloading scikit_learn-0.22.2.post1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 46.5 MB/s eta 0:00:00\n",
      "Collecting inference-schema[numpy-support]\n",
      "  Downloading inference_schema-1.4.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting scipy>=0.17.0\n",
      "  Downloading scipy-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.4/43.4 MB 33.8 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 500.6/500.6 kB 49.3 MB/s eta 0:00:00\n",
      "Collecting python-dateutil>=2.8.1\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 35.5 MB/s eta 0:00:00\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 8.0 MB/s eta 0:00:00\n",
      "Collecting packaging\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.8/40.8 kB 5.5 MB/s eta 0:00:00\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-4.21.5-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 408.4/408.4 kB 50.4 MB/s eta 0:00:00\n",
      "Collecting flatbuffers\n",
      "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.5/6.5 MB 46.9 MB/s eta 0:00:00\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.10.1-py3-none-any.whl (27 kB)\n",
      "Collecting pyopenssl<23.0.0\n",
      "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting humanfriendly<11.0,>=4.7\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 17.6 MB/s eta 0:00:00\n",
      "Collecting requests[socks]<3.0.0,>=2.19.1\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 kB 11.7 MB/s eta 0:00:00\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.4/141.4 kB 24.7 MB/s eta 0:00:00\n",
      "Collecting azure-common<2.0.0,>=1.1.12\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<38.0.0\n",
      "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.1/4.1 MB 46.4 MB/s eta 0:00:00\n",
      "Collecting jmespath<=1.0.0\n",
      "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting azure-mgmt-keyvault<11.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-10.1.0-py3-none-any.whl (605 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 605.9/605.9 kB 54.9 MB/s eta 0:00:00\n",
      "Collecting paramiko<3.0.0,>=2.0.8\n",
      "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.9/212.9 kB 34.3 MB/s eta 0:00:00\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pkginfo\n",
      "  Downloading pkginfo-1.8.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Collecting knack~=0.9.0\n",
      "  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.8/59.8 kB 9.5 MB/s eta 0:00:00\n",
      "Collecting azure-mgmt-authorization<3,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 465.2/465.2 kB 47.3 MB/s eta 0:00:00\n",
      "Collecting jsonpickle<3.0.0\n",
      "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting msrest<=0.7.1,>=0.5.1\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.4/85.4 kB 18.0 MB/s eta 0:00:00\n",
      "Collecting urllib3<=1.26.9,>=1.23\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.0/139.0 kB 24.9 MB/s eta 0:00:00\n",
      "Collecting msal-extensions<=1.0.0,>=0.3.0\n",
      "  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
      "Collecting msal<2.0.0,>=1.15.0\n",
      "  Downloading msal-1.18.0-py2.py3-none-any.whl (82 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.4/82.4 kB 12.1 MB/s eta 0:00:00\n",
      "Collecting azure-mgmt-resource<22.0.0,>=15.0.0\n",
      "  Downloading azure_mgmt_resource-21.1.0-py3-none-any.whl (1.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 54.9 MB/s eta 0:00:00\n",
      "Collecting azure-mgmt-storage<=20.0.0,>=16.0.0\n",
      "  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 54.9 MB/s eta 0:00:00\n",
      "Collecting azure-core<2.0.0\n",
      "  Downloading azure_core-1.25.1-py3-none-any.whl (178 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 178.8/178.8 kB 31.1 MB/s eta 0:00:00\n",
      "Collecting ndg-httpsclient<=0.5.1\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting contextlib2<22.0.0\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting argcomplete<3\n",
      "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting azure-mgmt-containerregistry<11,>=8.2.0\n",
      "  Downloading azure_mgmt_containerregistry-10.0.0-py3-none-any.whl (1.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 53.6 MB/s eta 0:00:00\n",
      "Collecting msrestazure<=0.6.4,>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.5/40.5 kB 7.3 MB/s eta 0:00:00\n",
      "Collecting adal<=1.2.7,>=1.2.0\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.5/55.5 kB 9.8 MB/s eta 0:00:00\n",
      "Collecting docker<6.0.0\n",
      "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 146.2/146.2 kB 26.5 MB/s eta 0:00:00\n",
      "Collecting azureml-telemetry\n",
      "  Downloading azureml_telemetry-1.45.0-py3-none-any.whl (30 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.44.0\n",
      "  Downloading azureml_dataset_runtime-1.44.0-py3-none-any.whl (2.3 kB)\n",
      "Collecting azureml-inference-server-http~=0.7.2\n",
      "  Downloading azureml_inference_server_http-0.7.5-py3-none-any.whl (56 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.7/56.7 kB 8.5 MB/s eta 0:00:00\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting wrapt<=1.12.1,>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting six>=1.11.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting typing-extensions>=4.0.1\n",
      "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
      "  Downloading azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\n",
      "Collecting azureml-dataprep<4.3.0a,>=4.2.0a\n",
      "  Downloading azureml_dataprep-4.2.2-py3-none-any.whl (43.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.4/43.4 MB 33.6 MB/s eta 0:00:00\n",
      "Collecting pyarrow<6.0.1,>=0.17.0\n",
      "  Downloading pyarrow-6.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 25.6/25.6 MB 38.8 MB/s eta 0:00:00\n",
      "Collecting fusepy<4.0.0,>=3.0.1\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting flask-cors~=3.0.1\n",
      "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
      "Collecting opencensus-ext-azure~=1.1.0\n",
      "  Downloading opencensus_ext_azure-1.1.7-py2.py3-none-any.whl (42 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.8/42.8 kB 6.0 MB/s eta 0:00:00\n",
      "Collecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 15.2 MB/s eta 0:00:00\n",
      "Collecting flask<2.2.0\n",
      "  Downloading Flask-2.1.3-py3-none-any.whl (95 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.6/95.6 kB 16.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools>=3.0 in /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/python3.8/site-packages (from gunicorn==20.1.0->azureml-inference-server-http~=0.7.2->azureml-defaults~=1.44.0->-r /azureml-environment-setup/condaenv.9eivtxd_.requirements.txt (line 7)) (61.2.0)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 442.7/442.7 kB 43.5 MB/s eta 0:00:00\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.0/55.0 kB 9.5 MB/s eta 0:00:00\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 46.3 MB/s eta 0:00:00\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 701.2/701.2 kB 50.1 MB/s eta 0:00:00\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "Collecting portalocker<3,>=1.0\n",
      "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.7/41.7 kB 7.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/python3.8/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.44.0->-r /azureml-environment-setup/condaenv.9eivtxd_.requirements.txt (line 5)) (2022.6.15)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 kB 7.1 MB/s eta 0:00:00\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.3/98.3 kB 9.5 MB/s eta 0:00:00\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 856.7/856.7 kB 53.9 MB/s eta 0:00:00\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-4.0.0-cp36-abi3-manylinux_2_28_x86_64.whl (594 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 594.4/594.4 kB 47.1 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 10.7 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.4/48.4 kB 8.1 MB/s eta 0:00:00\n",
      "Collecting applicationinsights\n",
      "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.1/55.1 kB 8.3 MB/s eta 0:00:00\n",
      "Collecting azureml-telemetry\n",
      "  Downloading azureml_telemetry-1.44.0-py3-none-any.whl (30 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 532.6/532.6 kB 47.1 MB/s eta 0:00:00\n",
      "Collecting jsonschema\n",
      "  Downloading jsonschema-4.15.0-py3-none-any.whl (82 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.7/82.7 kB 15.5 MB/s eta 0:00:00\n",
      "Collecting azure-identity==1.7.0\n",
      "  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 129.1/129.1 kB 21.9 MB/s eta 0:00:00\n",
      "Collecting cloudpickle<3.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting azureml-dataprep-native<39.0.0,>=38.0.0\n",
      "  Downloading azureml_dataprep_native-38.0.0-cp38-cp38-manylinux1_x86_64.whl (1.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 53.0 MB/s eta 0:00:00\n",
      "Collecting azureml-dataprep-rslex~=2.8.0dev0\n",
      "  Downloading azureml_dataprep_rslex-2.8.1-cp38-cp38-manylinux2010_x86_64.whl (16.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.5/16.5 MB 44.8 MB/s eta 0:00:00\n",
      "Collecting dotnetcore2<4.0.0,>=3.0.0\n",
      "  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 31.1/31.1 MB 36.9 MB/s eta 0:00:00\n",
      "Collecting msal-extensions<=1.0.0,>=0.3.0\n",
      "  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 118.7/118.7 kB 20.2 MB/s eta 0:00:00\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 232.7/232.7 kB 45.4 MB/s eta 0:00:00\n",
      "Collecting click>=8.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 kB 15.4 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata>=3.6.0\n",
      "  Downloading importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
      "Collecting psutil>=5.6.3\n",
      "  Downloading psutil-5.9.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (284 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 284.8/284.8 kB 39.2 MB/s eta 0:00:00\n",
      "Collecting opencensus<1.0.0,>=0.11.0\n",
      "  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.2/128.2 kB 16.8 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.5/151.5 kB 22.6 MB/s eta 0:00:00\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0\n",
      "  Downloading google_api_core-2.10.0-py3-none-any.whl (115 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 115.3/115.3 kB 25.2 MB/s eta 0:00:00\n",
      "Collecting opencensus-context>=0.1.3\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting attrs>=17.4.0\n",
      "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 10.3 MB/s eta 0:00:00\n",
      "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "  Downloading pyrsistent-0.18.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 kB 20.8 MB/s eta 0:00:00\n",
      "Collecting pkgutil-resolve-name>=1.3.10\n",
      "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "Collecting importlib-resources>=1.4.0\n",
      "  Downloading importlib_resources-5.9.0-py3-none-any.whl (33 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.7/211.7 kB 33.3 MB/s eta 0:00:00\n",
      "Collecting google-auth<3.0dev,>=1.25.0\n",
      "  Downloading google_auth-2.11.0-py2.py3-none-any.whl (167 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.2/167.2 kB 31.1 MB/s eta 0:00:00\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 27.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: azureml-monitoring, json-logging-py, wrapt, fusepy\n",
      "  Building wheel for azureml-monitoring (setup.py): started\n",
      "  Building wheel for azureml-monitoring (setup.py): finished with status 'done'\n",
      "  Created wheel for azureml-monitoring: filename=azureml_monitoring-0.1.0a21-py2.py3-none-any.whl size=14662509 sha256=27ec18342cc9f3139bef11eebc56b7d9d472570db6f36d1eb648aeaf3c5bfa6f\n",
      "  Stored in directory: /root/.cache/pip/wheels/b3/7c/c2/d4fe9da3626f2556e8b18eb5b7cdcfa17ee8565de8b3c45a3f\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=781d803aeadb6258ae46f62344a4decf24f9c5690cee5221e619f9b89e3e72d0\n",
      "  Stored in directory: /root/.cache/pip/wheels/e9/d6/70/7491901d808e74dd9238e4a91658ba108e4b5939b55327e6fb\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=81720 sha256=3939a2ace5fb5b71d90a16538b97b7e68f25c1dbcdef1e91d1c1c42953eb6db6\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=3f05214e5013917e158a59ad1caf363a69cf92959b627e2625bdf43496c3811e\n",
      "  Stored in directory: /root/.cache/pip/wheels/7f/41/10/f70b83a1164fdb95e7bc37bace13114a024227e56c2fee02bb\n",
      "Successfully built azureml-monitoring json-logging-py wrapt fusepy\n",
      "Installing collected packages: wrapt, pytz, pyasn1, opencensus-context, mpmath, json-logging-py, fusepy, flatbuffers, backports.weakref, azureml-dataprep-rslex, azureml-dataprep-native, azure-common, applicationinsights, zipp, websocket-client, urllib3, typing-extensions, tabulate, sympy, six, rsa, pyyaml, PySocks, pyrsistent, pyparsing, PyJWT, pygments, pycparser, pyasn1-modules, psutil, protobuf, portalocker, pkgutil-resolve-name, pkginfo, pathspec, oauthlib, numpy, MarkupSafe, jsonpickle, joblib, jmespath, jeepney, itsdangerous, idna, humanfriendly, gunicorn, distro, contextlib2, configparser, cloudpickle, click, charset-normalizer, cachetools, bcrypt, backports.tempfile, attrs, argcomplete, Werkzeug, scipy, requests, python-dateutil, pyarrow, packaging, knack, Jinja2, isodate, importlib-resources, importlib-metadata, googleapis-common-protos, google-auth, dotnetcore2, coloredlogs, cffi, scikit-learn, requests-oauthlib, pynacl, pandas, onnxruntime, jsonschema, inference-schema, google-api-core, flask, docker, cryptography, azure-core, SecretStorage, pyopenssl, paramiko, opencensus, msrest, flask-cors, azure-mgmt-core, adal, ndg-httpsclient, msrestazure, msal, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, msal-extensions, azure-graphrbac, azureml-core, azure-identity, opencensus-ext-azure, azureml-telemetry, azureml-dataprep, azureml-monitoring, azureml-inference-server-http, azureml-dataset-runtime, azureml-defaults\n",
      "Successfully installed Jinja2-3.0.3 MarkupSafe-2.1.1 PyJWT-2.4.0 PySocks-1.7.1 SecretStorage-3.3.3 Werkzeug-2.2.2 adal-1.2.7 applicationinsights-0.11.10 argcomplete-2.0.0 attrs-22.1.0 azure-common-1.1.28 azure-core-1.25.1 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-10.0.0 azure-mgmt-core-1.3.2 azure-mgmt-keyvault-10.1.0 azure-mgmt-resource-21.1.0 azure-mgmt-storage-20.0.0 azureml-core-1.44.0 azureml-dataprep-4.2.2 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.8.1 azureml-dataset-runtime-1.44.0 azureml-defaults-1.44.0 azureml-inference-server-http-0.7.5 azureml-monitoring-0.1.0a21 azureml-telemetry-1.44.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.0 cachetools-5.2.0 cffi-1.15.1 charset-normalizer-2.1.1 click-8.1.3 cloudpickle-2.2.0 coloredlogs-15.0.1 configparser-3.7.4 contextlib2-21.6.0 cryptography-37.0.4 distro-1.7.0 docker-5.0.3 dotnetcore2-3.1.23 flask-2.1.3 flask-cors-3.0.10 flatbuffers-2.0.7 fusepy-3.0.1 google-api-core-2.10.0 google-auth-2.11.0 googleapis-common-protos-1.56.4 gunicorn-20.1.0 humanfriendly-10.0 idna-3.3 importlib-metadata-4.12.0 importlib-resources-5.9.0 inference-schema-1.4.2.1 isodate-0.6.1 itsdangerous-2.1.2 jeepney-0.8.0 jmespath-1.0.0 joblib-1.1.0 json-logging-py-0.2 jsonpickle-2.2.0 jsonschema-4.15.0 knack-0.9.0 mpmath-1.2.1 msal-1.18.0 msal-extensions-0.3.1 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.23.2 oauthlib-3.2.0 onnxruntime-1.12.1 opencensus-0.11.0 opencensus-context-0.1.3 opencensus-ext-azure-1.1.7 packaging-21.3 pandas-1.4.4 paramiko-2.11.0 pathspec-0.10.1 pkginfo-1.8.3 pkgutil-resolve-name-1.3.10 portalocker-2.5.1 protobuf-4.21.5 psutil-5.9.2 pyarrow-6.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pygments-2.13.0 pynacl-1.5.0 pyopenssl-22.0.0 pyparsing-3.0.9 pyrsistent-0.18.1 python-dateutil-2.8.2 pytz-2022.2.1 pyyaml-6.0 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 scikit-learn-0.22.2.post1 scipy-1.9.1 six-1.16.0 sympy-1.11.1 tabulate-0.8.10 typing-extensions-4.3.0 urllib3-1.26.9 websocket-client-1.4.1 wrapt-1.12.1 zipp-3.8.1\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.11.0\n",
      "  latest version: 4.14.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_1867cd816376033961c66f81bff348cf\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "WARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container 0e3f5e000e39\n",
      " ---> 4163611f1ca0\n",
      "Step 9/21 : ENV PATH /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/bin:$PATH\n",
      " ---> Running in d342e014283a\n",
      "Removing intermediate container d342e014283a\n",
      " ---> 2a6f2fefb5bf\n",
      "Step 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> 9a75fde0cfe5\n",
      "Step 11/21 : RUN echo \"Copying environment context\"\n",
      " ---> Running in badfdc07a933\n",
      "Copying environment context\n",
      "Removing intermediate container badfdc07a933\n",
      " ---> 3dacf470a67d\n",
      "Step 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> 564fa80deb04\n",
      "Step 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_1867cd816376033961c66f81bff348cf\n",
      " ---> Running in 21378b04ad63\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container 21378b04ad63\n",
      " ---> cbdee3838fd5\n",
      "Step 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_1867cd816376033961c66f81bff348cf\n",
      " ---> Running in b79ba8b0311c\n",
      "Removing intermediate container b79ba8b0311c\n",
      " ---> 1a7e854a6d31\n",
      "Step 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 27bc8ca3f270\n",
      "Removing intermediate container 27bc8ca3f270\n",
      " ---> c2da15f44f99\n",
      "Step 16/21 : ENV CONDA_DEFAULT_ENV=azureml_1867cd816376033961c66f81bff348cf CONDA_PREFIX=/azureml-envs/azureml_1867cd816376033961c66f81bff348cf\n",
      " ---> Running in cf4c7fb5b841\n",
      "Removing intermediate container cf4c7fb5b841\n",
      " ---> 9ae3ade41d61\n",
      "Step 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 507f5756e0a1\n",
      "Step 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 19722a525416\n",
      "Removing intermediate container 19722a525416\n",
      " ---> 46add5857698\n",
      "Step 19/21 : RUN rm -rf azureml-environment-setup\n",
      " ---> Running in 397d9f8c4bea\n",
      "Removing intermediate container 397d9f8c4bea\n",
      " ---> 2a2e66677049\n",
      "Step 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 8ca20d20b02e\n",
      "Removing intermediate container 8ca20d20b02e\n",
      " ---> 0634e31d52e8\n",
      "Step 21/21 : CMD [\"bash\"]\n",
      " ---> Running in b16b49c43f57\n",
      "Removing intermediate container b16b49c43f57\n",
      " ---> 3651c9bb2c4a\n",
      "Successfully built 3651c9bb2c4a\n",
      "Successfully tagged 466eacc5059a407f8aeb4439774e2354.azurecr.io/azureml/azureml_44403a36f69d445806d69e506c1210a0:latest\n",
      "Successfully tagged 466eacc5059a407f8aeb4439774e2354.azurecr.io/azureml/azureml_44403a36f69d445806d69e506c1210a0:1\n",
      "2022/09/09 03:58:42 Successfully executed container: acb_step_0\n",
      "2022/09/09 03:58:42 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/09/09 03:58:42 Pushing image: 466eacc5059a407f8aeb4439774e2354.azurecr.io/azureml/azureml_44403a36f69d445806d69e506c1210a0:1, attempt 1\n",
      "The push refers to repository [466eacc5059a407f8aeb4439774e2354.azurecr.io/azureml/azureml_44403a36f69d445806d69e506c1210a0]\n",
      "adf66820a4b8: Preparing\n",
      "96761f8f5f3d: Preparing\n",
      "f490cfe1f36b: Preparing\n",
      "13a9e29147ec: Preparing\n",
      "4720ed5efe38: Preparing\n",
      "069ae35d7275: Preparing\n",
      "67ec6d6e4124: Preparing\n",
      "0ff84b1bbb2f: Preparing\n",
      "bb12ec3c5a76: Preparing\n",
      "b9bf6fd35dcd: Preparing\n",
      "cc45347b4ace: Preparing\n",
      "1b372d66233e: Preparing\n",
      "07a28cde7d10: Preparing\n",
      "30396212e2bd: Preparing\n",
      "e2efb02e0592: Preparing\n",
      "dafbdffeff20: Preparing\n",
      "657ccef222ea: Preparing\n",
      "a2fbf4296693: Preparing\n",
      "149bb2b607d0: Preparing\n",
      "af7ed92504ae: Preparing\n",
      "069ae35d7275: Waiting\n",
      "67ec6d6e4124: Waiting\n",
      "0ff84b1bbb2f: Waiting\n",
      "1b372d66233e: Waiting\n",
      "bb12ec3c5a76: Waiting\n",
      "b9bf6fd35dcd: Waiting\n",
      "cc45347b4ace: Waiting\n",
      "07a28cde7d10: Waiting\n",
      "30396212e2bd: Waiting\n",
      "657ccef222ea: Waiting\n",
      "e2efb02e0592: Waiting\n",
      "a2fbf4296693: Waiting\n",
      "149bb2b607d0: Waiting\n",
      "af7ed92504ae: Waiting\n",
      "dafbdffeff20: Waiting\n",
      "13a9e29147ec: Pushed\n",
      "4720ed5efe38: Pushed\n",
      "96761f8f5f3d: Pushed\n",
      "adf66820a4b8: Pushed\n",
      "bb12ec3c5a76: Pushed\n",
      "67ec6d6e4124: Pushed\n",
      "f490cfe1f36b: Pushed\n",
      "0ff84b1bbb2f: Pushed\n",
      "b9bf6fd35dcd: Pushed\n",
      "cc45347b4ace: Pushed\n",
      "1b372d66233e: Pushed\n",
      "dafbdffeff20: Pushed\n",
      "07a28cde7d10: Pushed\n",
      "30396212e2bd: Pushed\n",
      "657ccef222ea: Pushed\n",
      "e2efb02e0592: Pushed\n",
      "a2fbf4296693: Pushed\n",
      "af7ed92504ae: Pushed\n",
      "149bb2b607d0: Pushed\n",
      "069ae35d7275: Pushed\n",
      "1: digest: sha256:f664ca7387a66b4a2175351ed2d212d2045d0311088c1a680e6fb482e46ea30e size: 4513\n",
      "2022/09/09 03:59:52 Successfully pushed image: 466eacc5059a407f8aeb4439774e2354.azurecr.io/azureml/azureml_44403a36f69d445806d69e506c1210a0:1\n",
      "2022/09/09 03:59:52 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/09/09 03:59:52 Pushing image: 466eacc5059a407f8aeb4439774e2354.azurecr.io/azureml/azureml_44403a36f69d445806d69e506c1210a0:latest, attempt 1\n",
      "The push refers to repository [466eacc5059a407f8aeb4439774e2354.azurecr.io/azureml/azureml_44403a36f69d445806d69e506c1210a0]\n",
      "adf66820a4b8: Preparing\n",
      "96761f8f5f3d: Preparing\n",
      "f490cfe1f36b: Preparing\n",
      "13a9e29147ec: Preparing\n",
      "4720ed5efe38: Preparing\n",
      "069ae35d7275: Preparing\n",
      "67ec6d6e4124: Preparing\n",
      "0ff84b1bbb2f: Preparing\n",
      "bb12ec3c5a76: Preparing\n",
      "b9bf6fd35dcd: Preparing\n",
      "cc45347b4ace: Preparing\n",
      "1b372d66233e: Preparing\n",
      "07a28cde7d10: Preparing\n",
      "30396212e2bd: Preparing\n",
      "e2efb02e0592: Preparing\n",
      "dafbdffeff20: Preparing\n",
      "657ccef222ea: Preparing\n",
      "a2fbf4296693: Preparing\n",
      "149bb2b607d0: Preparing\n",
      "af7ed92504ae: Preparing\n",
      "07a28cde7d10: Waiting\n",
      "30396212e2bd: Waiting\n",
      "e2efb02e0592: Waiting\n",
      "dafbdffeff20: Waiting\n",
      "657ccef222ea: Waiting\n",
      "069ae35d7275: Waiting\n",
      "a2fbf4296693: Waiting\n",
      "67ec6d6e4124: Waiting\n",
      "0ff84b1bbb2f: Waiting\n",
      "149bb2b607d0: Waiting\n",
      "af7ed92504ae: Waiting\n",
      "cc45347b4ace: Waiting\n",
      "bb12ec3c5a76: Waiting\n",
      "1b372d66233e: Waiting\n",
      "13a9e29147ec: Layer already exists\n",
      "f490cfe1f36b: Layer already exists\n",
      "96761f8f5f3d: Layer already exists\n",
      "adf66820a4b8: Layer already exists\n",
      "4720ed5efe38: Layer already exists\n",
      "069ae35d7275: Layer already exists\n",
      "67ec6d6e4124: Layer already exists\n",
      "bb12ec3c5a76: Layer already exists\n",
      "b9bf6fd35dcd: Layer already exists\n",
      "0ff84b1bbb2f: Layer already exists\n",
      "1b372d66233e: Layer already exists\n",
      "cc45347b4ace: Layer already exists\n",
      "30396212e2bd: Layer already exists\n",
      "07a28cde7d10: Layer already exists\n",
      "dafbdffeff20: Layer already exists\n",
      "e2efb02e0592: Layer already exists\n",
      "149bb2b607d0: Layer already exists\n",
      "657ccef222ea: Layer already exists\n",
      "a2fbf4296693: Layer already exists\n",
      "af7ed92504ae: Layer already exists\n",
      "latest: digest: sha256:f664ca7387a66b4a2175351ed2d212d2045d0311088c1a680e6fb482e46ea30e size: 4513\n",
      "2022/09/09 03:59:53 Successfully pushed image: 466eacc5059a407f8aeb4439774e2354.azurecr.io/azureml/azureml_44403a36f69d445806d69e506c1210a0:latest\n",
      "2022/09/09 03:59:53 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 214.475396)\n",
      "2022/09/09 03:59:53 Populating digests for step ID: acb_step_0...\n",
      "2022/09/09 03:59:54 Successfully populated digests for step ID: acb_step_0\n",
      "2022/09/09 03:59:54 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 69.751825)\n",
      "2022/09/09 03:59:54 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.122003)\n",
      "2022/09/09 03:59:54 The following dependencies were found:\n",
      "2022/09/09 03:59:54 \n",
      "- image:\n",
      "    registry: 466eacc5059a407f8aeb4439774e2354.azurecr.io\n",
      "    repository: azureml/azureml_44403a36f69d445806d69e506c1210a0\n",
      "    tag: latest\n",
      "    digest: sha256:f664ca7387a66b4a2175351ed2d212d2045d0311088c1a680e6fb482e46ea30e\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi4.1.0-ubuntu20.04\n",
      "    tag: 20220708.v1\n",
      "    digest: sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: 466eacc5059a407f8aeb4439774e2354.azurecr.io\n",
      "    repository: azureml/azureml_44403a36f69d445806d69e506c1210a0\n",
      "    tag: \"1\"\n",
      "    digest: sha256:f664ca7387a66b4a2175351ed2d212d2045d0311088c1a680e6fb482e46ea30e\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi4.1.0-ubuntu20.04\n",
      "    tag: 20220708.v1\n",
      "    digest: sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cu1 was successful after 4m50s\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry 466eacc5059a407f8aeb4439774e2354.azurecr.io\n",
      "Logging into Docker registry 466eacc5059a407f8aeb4439774e2354.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM 466eacc5059a407f8aeb4439774e2354.azurecr.io/azureml/azureml_44403a36f69d445806d69e506c1210a0\n",
      " ---> 3651c9bb2c4a\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 403a0ebfc22c\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjBkMTQ0MmMxLWQzODYtNDUwNS05YWJlLTBiZWRmZDYzNzAxZSIsInJlc291cmNlR3JvdXBOYW1lIjoic2FuamVldi1tbG9wcyIsImFjY291bnROYW1lIjoic2FuamVldi1tbG9wcyIsIndvcmtzcGFjZUlkIjoiNDY2ZWFjYzUtMDU5YS00MDdmLThhZWItNDQzOTc3NGUyMzU0In0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 0042cd3e9d16\n",
      " ---> 26f39ebcb199\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpa_93iq80.py' /var/azureml-app/main.py\n",
      " ---> Running in a8eb4e6a97ab\n",
      " ---> 1fbbf2426726\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 5bc12c704ffb\n",
      " ---> d62ffc148ee0\n",
      "Successfully built d62ffc148ee0\n",
      "Successfully tagged test:latest\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6601\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "\n",
    "model_dt_iris = Model(ws, 'iris-predictor-dt')\n",
    "# This is optional, if not provided Docker will choose a random unused port.\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6601)\n",
    "\n",
    "local_service = Model.deploy(ws, \"test\", [model_dt_iris], inference_config, deployment_config)\n",
    "\n",
    "local_service.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88b3f8e4-2947-4923-9524-795df3bfbbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "#input_data = pd.DataFrame({'sepal.length': [5.1, 1.1], 'sepal.width': [3.5, 2.8], 'petal.length' : [1.4, 4.4], 'petal.width' : [0.2, 1.2]})\n",
    "input_data = {'sepal.length': [5.1, 1.1], 'sepal.width': [3.5, 2.8], 'petal.length' : [1.4, 4.4], 'petal.width' : [0.2, 1.2] }\n",
    "                          #[{'sepal.length': [5.1, 1.1], 'sepal.width': [3.5, 2.8], 'petal.length' : [1.4, 4.4], 'petal.width' : [0.2, 1.2]}]}} #{'data' : {'sepal.length': [5.1, 1.1], 'sepal.width': [3.5, 2.8], 'petal.length' : [1.4, 4.4], 'petal.width' : [0.2, 1.2]] }\n",
    "\n",
    "request = {\"Inputs\": {\"data\" : [[5.1, 3.5, 1.4, 0.2], [1.1, 2.8, 4.4, 1.2] ] }}\n",
    "\n",
    "headers = {'Content-Type': 'application/json', 'Accept': 'text/plain'}\n",
    "\n",
    "scoring_uri = \"http://localhost:6601/score\"\n",
    "resp = requests.post(scoring_uri, json.dumps(request), headers=headers)\n",
    "\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a3ff16-564a-402b-ba68-cac38a8cf9ce",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/72376401/making-predictions-with-azure-machine-learning-with-new-data-that-contains-heade\n",
    "https://stackoverflow.com/questions/64257530/import-data-and-python-scripts-in-azure-ml-entry-script-when-deploying-models\n",
    "https://docs.microsoft.com/en-us/answers/questions/746784/azure-ml-studio-error-while-testing-real-time-endp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f668c4-3510-4f55-85a7-3ee67b30eb0f",
   "metadata": {},
   "source": [
    "## Model profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b90105c6-6b2f-4811-bf76-a66412c98352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading dataset/profile-data/model-profiling-data-v1.txt\n",
      "Uploaded dataset/profile-data/model-profiling-data-v1.txt, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_5d5b05aee0224d4bb210088eeafaab62"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from azureml.core import Datastore\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.data import dataset_type_definitions\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "input_json = {\"Inputs\": {\"data\" : [[5.1, 3.5, 1.4, 0.2], [1.1, 2.8, 4.4, 1.2] ] }}\n",
    "\n",
    "serialized_input_json = json.dumps(input_json)\n",
    "dataset_content = []\n",
    "\n",
    "for i in range(100):\n",
    "     dataset_content.append(serialized_input_json)\n",
    "\n",
    "\n",
    "dataset_content = '\\n'.join(dataset_content)\n",
    "\n",
    "with open('./dataset/profile-data/model-profiling-data-v1.txt', 'w') as f:\n",
    "    f.write(dataset_content)\n",
    "\n",
    "\n",
    "# upload the txt file created above to the Datastore and create a dataset from it\n",
    "datastore = ws.get_default_datastore() # points to the native Azure ML Storage\n",
    "datastore.upload(src_dir = 'dataset/profile-data/', target_path = 'iris_model_profiling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b2fdb5a-d9d2-49e1-9305-7b9719805003",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_request_data = Dataset.Tabular.from_delimited_files(datastore.path('iris_model_profiling/model-profiling-data-v1.txt'), separator='\\n',\n",
    "                                                           infer_column_types=True,\n",
    "                                                          header=dataset_type_definitions.PromoteHeadersBehavior.NO_HEADERS)\n",
    "\n",
    "sample_request_data = sample_request_data.register(workspace=ws, name='iris-profiling-data', create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8407f7a-3024-4fe8-8dda-921e714da000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running........................................................\n",
      "Succeeded\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core import Workspace, Environment\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "iris_env = Environment.get(ws, name = 'iris-env')\n",
    "\n",
    "model = Model(ws, name = 'iris-predictor-dt')\n",
    "inference_config = InferenceConfig(entry_script='score_v2.py',\n",
    "                                   environment = iris_env)\n",
    "\n",
    "input_dataset = Dataset.get_by_name(workspace=ws, name='iris-profiling-data') #dataset should be in the string format hence the above exercise\n",
    "profile = Model.profile(ws,\n",
    "            'iris-model-profile-2',\n",
    "            [model],\n",
    "            inference_config,\n",
    "            input_dataset=input_dataset)\n",
    "\n",
    "profile.wait_for_completion(True)\n",
    "\n",
    "# see the result\n",
    "details = profile.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d88b406d-bffb-4400-aa0e-5c78f995c7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'iris-model-profile-2',\n",
       " 'createdTime': '2022-09-09T04:10:31.886632+00:00',\n",
       " 'state': 'Succeeded',\n",
       " 'requestedCpu': 3.5,\n",
       " 'requestedMemoryInGB': 15.0,\n",
       " 'requestedQueriesPerSecond': 0,\n",
       " 'maxUtilizedMemoryInGB': 0.19586389333333334,\n",
       " 'totalQueries': 100.0,\n",
       " 'successQueries': 100.0,\n",
       " 'successRate': 100.0,\n",
       " 'averageLatencyInMs': 4.7376000000000005,\n",
       " 'latencyPercentile50InMs': 3.15,\n",
       " 'latencyPercentile90InMs': 4.12,\n",
       " 'latencyPercentile95InMs': 5.65,\n",
       " 'latencyPercentile99InMs': 40.02,\n",
       " 'latencyPercentile999InMs': 40.02,\n",
       " 'maxUtilizedCpu': 0.14733333333333334,\n",
       " 'measuredQueriesPerSecond': 211.07733873691316,\n",
       " 'recommendedMemoryInGB': 0.5,\n",
       " 'recommendedCpu': 0.5}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6a6d6-db47-487b-8899-e7a79b1d2a4d",
   "metadata": {},
   "source": [
    "## AKS With Data Drift Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "977aadfc-5d55-4026-9b6e-d30b4a28ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress..................................................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "compute_config = AksCompute.provisioning_configuration(location='centralindia', cluster_purpose='DevTest')\n",
    "cluster = ComputeTarget.create(ws, 'iris-aks', compute_config)\n",
    "cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19594d8d-28d0-4baf-a73d-0fae6cbaab1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-09-09 04:24:42+00:00 Creating Container Registry if not exists.\n",
      "2022-09-09 04:24:42+00:00 Registering the environment.\n",
      "2022-09-09 04:24:45+00:00 Use the existing image for iris-endpoint.\n",
      "2022-09-09 04:24:46+00:00 Creating resources in AKS..\n",
      "2022-09-09 04:24:47+00:00 Submitting deployment to compute.\n",
      "2022-09-09 04:24:48+00:00 Checking the status of deployment iris-endpoint..\n",
      "2022-09-09 04:26:37+00:00 Checking the status of inference endpoint iris-endpoint.\n",
      "Succeeded\n",
      "AKSENDPOINT service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "{\"iris-endpoint\":\"/bin/bash: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n2022-09-09T04:26:32,228861072+00:00 - iot-server/run \\n2022-09-09T04:26:32,228845172+00:00 - rsyslog/run \\n2022-09-09T04:26:32,242597956+00:00 - gunicorn/run \\n2022-09-09T04:26:32,244212065+00:00 | gunicorn/run | \\n2022-09-09T04:26:32,245621374+00:00 | gunicorn/run | ###############################################\\n2022-09-09T04:26:32,246946582+00:00 | gunicorn/run | AzureML Container Runtime Information\\n2022-09-09T04:26:32,248464191+00:00 | gunicorn/run | ###############################################\\n2022-09-09T04:26:32,249902400+00:00 | gunicorn/run | \\n2022-09-09T04:26:32,252667316+00:00 | gunicorn/run | \\nbash: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/libtinfo.so.6: no version information available (required by bash)\\n2022-09-09T04:26:32,278160471+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20220708.v2\\n2022-09-09T04:26:32,279663680+00:00 | gunicorn/run | \\n2022-09-09T04:26:32,281133589+00:00 | gunicorn/run | \\n2022-09-09T04:26:32,282975800+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\n2022-09-09T04:26:32,284584809+00:00 | gunicorn/run | PYTHONPATH environment variable: \\n2022-09-09T04:26:32,286109919+00:00 | gunicorn/run | \\n2022-09-09T04:26:32,287634128+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\\n\\n2022-09-09T04:26:32,329921684+00:00 - nginx/run \\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n/bin/bash: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n2022-09-09T04:26:32,434611817+00:00 - iot-server/finish 1 0\\n2022-09-09T04:26:32,436064525+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nadal==1.2.7\\napplicationinsights==0.11.10\\nargcomplete==2.0.0\\nattrs==22.1.0\\nazure-common==1.1.28\\nazure-core==1.25.1\\nazure-graphrbac==0.61.1\\nazure-identity==1.7.0\\nazure-mgmt-authorization==2.0.0\\nazure-mgmt-containerregistry==10.0.0\\nazure-mgmt-core==1.3.2\\nazure-mgmt-keyvault==10.1.0\\nazure-mgmt-resource==21.1.0\\nazure-mgmt-storage==20.0.0\\nazureml-core==1.44.0\\nazureml-dataprep==4.2.2\\nazureml-dataprep-native==38.0.0\\nazureml-dataprep-rslex==2.8.1\\nazureml-dataset-runtime==1.44.0\\nazureml-defaults==1.44.0\\nazureml-inference-server-http==0.7.5\\nazureml-monitoring==0.1.0a21\\nazureml-telemetry==1.44.0\\nbackports.tempfile==1.0\\nbackports.weakref==1.0.post1\\nbcrypt==4.0.0\\ncachetools==5.2.0\\ncertifi @ file:///opt/conda/conda-bld/certifi_1655968806487/work/certifi\\ncffi==1.15.1\\ncharset-normalizer==2.1.1\\nclick==8.1.3\\ncloudpickle==2.2.0\\ncoloredlogs==15.0.1\\nconfigparser==3.7.4\\ncontextlib2==21.6.0\\ncryptography==37.0.4\\ndistro==1.7.0\\ndocker==5.0.3\\ndotnetcore2==3.1.23\\nFlask==2.1.3\\nFlask-Cors==3.0.10\\nflatbuffers==2.0.7\\nfusepy==3.0.1\\ngoogle-api-core==2.10.0\\ngoogle-auth==2.11.0\\ngoogleapis-common-protos==1.56.4\\ngunicorn==20.1.0\\nhumanfriendly==10.0\\nidna==3.3\\nimportlib-metadata==4.12.0\\nimportlib-resources==5.9.0\\ninference-schema==1.4.2.1\\nisodate==0.6.1\\nitsdangerous==2.1.2\\njeepney==0.8.0\\nJinja2==3.0.3\\njmespath==1.0.0\\njoblib==1.1.0\\njson-logging-py==0.2\\njsonpickle==2.2.0\\njsonschema==4.15.0\\nknack==0.9.0\\nMarkupSafe==2.1.1\\nmpmath==1.2.1\\nmsal==1.18.0\\nmsal-extensions==0.3.1\\nmsrest==0.7.1\\nmsrestazure==0.6.4\\nndg-httpsclient==0.5.1\\nnumpy==1.23.2\\noauthlib==3.2.0\\nonnxruntime==1.12.1\\nopencensus==0.11.0\\nopencensus-context==0.1.3\\nopencensus-ext-azure==1.1.7\\npackaging==21.3\\npandas==1.4.4\\nparamiko==2.11.0\\npathspec==0.10.1\\npkginfo==1.8.3\\npkgutil_resolve_name==1.3.10\\nportalocker==2.5.1\\nprotobuf==4.21.5\\npsutil==5.9.2\\npyarrow==6.0.0\\npyasn1==0.4.8\\npyasn1-modules==0.2.8\\npycparser==2.21\\nPygments==2.13.0\\nPyJWT==2.4.0\\nPyNaCl==1.5.0\\npyOpenSSL==22.0.0\\npyparsing==3.0.9\\npyrsistent==0.18.1\\nPySocks==1.7.1\\npython-dateutil==2.8.2\\npytz==2022.2.1\\nPyYAML==6.0\\nrequests==2.28.1\\nrequests-oauthlib==1.3.1\\nrsa==4.9\\nscikit-learn==0.22.2.post1\\nscipy==1.9.1\\nSecretStorage==3.3.3\\nsix==1.16.0\\nsympy==1.11.1\\ntabulate==0.8.10\\ntyping_extensions==4.3.0\\nurllib3==1.26.9\\nwebsocket-client==1.4.1\\nWerkzeug==2.2.2\\nwrapt==1.12.1\\nzipp==3.8.1\\n\\n2022-09-09T04:26:33,084963649+00:00 | gunicorn/run | \\n2022-09-09T04:26:33,086534159+00:00 | gunicorn/run | ###############################################\\n2022-09-09T04:26:33,088075268+00:00 | gunicorn/run | AzureML Inference Server\\n2022-09-09T04:26:33,089437876+00:00 | gunicorn/run | ###############################################\\n2022-09-09T04:26:33,090831885+00:00 | gunicorn/run | \\n2022-09-09T04:26:34,111342356+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\\n\\nAzure ML Inferencing HTTP server v0.7.5\\n\\n\\nServer Settings\\n---------------\\nEntry Script Name: main.py\\nModel Directory: /var/azureml-app/azureml-models/iris-predictor-dt/1\\nWorker Count: 1\\nWorker Timeout (seconds): 300\\nServer Port: 31311\\nApplication Insights Enabled: false\\nApplication Insights Key: AppInsights key provided\\nInferencing HTTP server version: azmlinfsrv/0.7.5\\nCORS for the specified origins: None\\n\\n\\nServer Routes\\n---------------\\nLiveness Probe: GET   127.0.0.1:31311/\\nScore:          POST  127.0.0.1:31311/score\\n\\nStarting gunicorn 20.1.0\\nListening at: http://0.0.0.0:31311 (15)\\nUsing worker: sync\\nBooting worker with pid: 68\\nInitializing logger\\n2022-09-09 04:26:34,793 | root | INFO | Starting up app insights client\\nlogging socket was found. logging is available.\\nlogging socket was found. logging is available.\\n2022-09-09 04:26:34,793 | root | INFO | Starting up app insight hooks\\n2022-09-09 04:26:36,074 | root | INFO | Found driver script at /var/azureml-app/main.py and the score script at /structure/azureml-app/score_v2.py\\n2022-09-09 04:26:36,074 | root | INFO | run() is decorated with @input_schema. Server will invoke it with the following arguments: Inputs.\\n2022-09-09 04:26:36,074 | root | INFO | Invoking user's init function\\n2022-09-09 04:26:36,079 | root | INFO | Users's init has completed successfully\\n2022-09-09 04:26:36,080 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\\n2022-09-09 04:26:36,080 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\n2022-09-09 04:26:36,080 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\\n2022-09-09 04:26:37,354 | root | INFO | 200\\n127.0.0.1 - - [09/Sep/2022:04:26:37 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 200 2891 \\\"-\\\" \\\"hackney/1.18.1\\\"\\n2022-09-09 04:26:42,363 | root | INFO | 200\\n127.0.0.1 - - [09/Sep/2022:04:26:42 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 200 2891 \\\"-\\\" \\\"hackney/1.18.1\\\"\\n\"}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AksWebservice, Webservice, AksEndpoint\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.compute import AksCompute\n",
    "\n",
    "aks_target = AksCompute(ws, 'iris-aks')\n",
    "\n",
    "model_v1 = Model(ws, 'iris-predictor-dt')\n",
    "inference_config_dt = InferenceConfig(entry_script='score_v2_AKS_dt.py',\n",
    "                                   environment = iris_env)\n",
    "\n",
    "# If deploying to a cluster configured for dev/test, ensure that it was created with enough\n",
    "# cores and memory to handle this deployment configuration. Note that memory is also used by\n",
    "# things such as dependencies and AML components.\n",
    "deployment_config = AksEndpoint.deploy_configuration(cpu_cores = 1, memory_gb = 0.5, collect_model_data = True)\n",
    "\n",
    "service = Model.deploy(ws, 'iris-endpoint', [model_v1], inference_config_dt, deployment_config, aks_target)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "\n",
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4748d6d8-04fc-457b-ac87-261f079b23d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "test_sample = json.dumps({\"Inputs\": {\"data\" : [[5.1, 3.5, 1.4, 0.2], [1.1, 2.8, 4.4, 1.2] ] }})\n",
    "\n",
    "test_sample_encoded = bytes(test_sample, encoding='utf8')\n",
    "prediction = service.run(input_data=test_sample_encoded)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caa517ac-3312-4501-bf55-51b8805a4dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-09-09 05:06:09+00:00 Creating Container Registry if not exists.\n",
      "2022-09-09 05:06:12+00:00 Registering the environment.\n",
      "2022-09-09 05:06:13+00:00 Use the existing image for iris-endpoint..\n",
      "2022-09-09 05:06:17+00:00 Checking the status of deployment iris-endpoint.\n",
      "2022-09-09 05:06:17+00:00 Checking the status of deployment version-2..\n",
      "2022-09-09 05:07:06+00:00 Checking the status of inference endpoint iris-endpoint.\n",
      "Succeeded\n",
      "AKSENDPOINT service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "model_v2 = Model(ws, 'iris-predictor-rfc')\n",
    "inference_config_rfc = InferenceConfig(entry_script='score_v2_AKS_RF.py',\n",
    "                                   environment = iris_env)\n",
    "\n",
    "service.create_version( version_name= 'version-2', inference_config=inference_config_rfc, models=[model_v2], description=\"With RF\", traffic_percentile=50)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b4c76fd-27c7-49ac-9abc-6901646abc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ModelDataCollector' object has no attribute '_cloud_enabled'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "test_sample = json.dumps({\"Inputs\": {\"data\" : [[5.1, 3.5, 1.4, 0.2], [1.1, 2.8, 4.4, 1.2] ] }})\n",
    "\n",
    "test_sample_encoded = bytes(test_sample, encoding='utf8')\n",
    "prediction = service.run(input_data=test_sample_encoded)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e3c9f-91d6-4ed0-9372-f0951e95949a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
