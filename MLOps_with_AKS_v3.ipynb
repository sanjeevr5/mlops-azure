{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe10eac-3e92-4d1f-afc8-3fcc3d77585e",
   "metadata": {},
   "source": [
    "# MLOps with AKS\n",
    "\n",
    "<b>Objective</b>\n",
    "\n",
    "\n",
    "1. To create a simple model to predict the category for IRIS dataset.\n",
    "2. To use Azure's capability to find the following:\n",
    " - Use dataset drifter to identiy whether there is a drift in the dataset.\n",
    " - If there is a drift then create an automatic email alert for the same.\n",
    " - Model profiling to get an approximation of the resources that might be required for our model.\n",
    " - Deploy the model on AKS with the above profiling values.\n",
    " - Use multiple versions of the best model to introduce AB testing kind of scenarios.\n",
    " - Monitoring using log analytics and application insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ca8d5-31fb-4a5a-9b23-d72df794bce5",
   "metadata": {},
   "source": [
    "## Part - I\n",
    "\n",
    "1. Download the IRIS dataset from the web.\n",
    "2. Convert the labels to numeric representations.\n",
    "3. Push the cleaned dataset to a new folder.\n",
    "4. Upload it to the default datastore of ML workspace.\n",
    "5. Register the dataset.\n",
    "6. Access the dataset to check everything is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aae1a0d-d46e-4dd7-9ca7-c324ebc3a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./dataset\n",
    "!mkdir ./dataset/inputs\n",
    "!mkdir ./dataset/processed_data\n",
    "!mkdir ./dataset/profile-data\n",
    "!mkdir ./model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9bce475-e373-4133-86c3-76b707c5edae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-09-08 15:32:16--  https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3975 (3.9K) [text/plain]\n",
      "Saving to: ‘./dataset/inputs/iris_raw.csv’\n",
      "\n",
      "./dataset/inputs/ir 100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-09-08 15:32:17 (57.5 MB/s) - ‘./dataset/inputs/iris_raw.csv’ saved [3975/3975]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O ./dataset/inputs/iris_raw.csv https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bac3b28-b338-4c9d-b65b-7ec083fd893f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0\n",
       "5           5.4          3.9           1.7          0.4        0\n",
       "6           4.6          3.4           1.4          0.3        0\n",
       "7           5.0          3.4           1.5          0.2        0\n",
       "8           4.4          2.9           1.4          0.2        0\n",
       "9           4.9          3.1           1.5          0.1        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "raw_data = pd.read_csv('./dataset/inputs/iris_raw.csv') #The shape of the data is (150,5) 4 features + 1 label\n",
    "i2l = dict(enumerate(raw_data.variety.unique().tolist()))\n",
    "l2i = {k:i for i, k in i2l.items()}\n",
    "raw_data.variety = raw_data.variety.map(lambda x : l2i[x])\n",
    "\n",
    "display(raw_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a7d7d7-d757-4f45-a3e5-f018c8250a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.to_csv('./dataset/processed_data/iris_data_base.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057bc585-b152-437f-9834-e31f42af694a",
   "metadata": {},
   "source": [
    "#(or)\n",
    "\"\"\"\n",
    "with open('./auth/azure_details.txt', 'r') as f:\n",
    "    vals = f.readlines()\n",
    "\n",
    "subscription_id = vals[0].strip('\\n')\n",
    "resource_group = vals[1].strip('\\n')\n",
    "workspace_name = vals[2] \n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a347ff56-ed80-493b-9b71-4fd461b4a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config() #we are in the same workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4020de50-609d-4467-bbc2-73da5b333368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./dataset/processed_data/iris_data_base.csv\n",
      "Uploaded ./dataset/processed_data/iris_data_base.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_fcd5f9cf77364c2ba6f90fd1745f58f6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "datastore = ws.get_default_datastore() # points to the native Azure ML Storage\n",
    "\n",
    "datastore.upload(src_dir = './dataset/processed_data', target_path = 'iris_data_base')\n",
    "\n",
    "#from azureml.core.datapath import DataPath\n",
    "#Datastore.get(workspace, 'workspaceblobstore')\n",
    "#iris_dataset = Dataset.File.upload_directory('./dataset/inputs/', DataPath(datastore, 'iris-base-data'), pattern = '*.csv') # for files dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ca59cbc-7191-4d4a-b42b-1c105331a069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'iris_data_base/iris_data_base.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"da8a1654-158b-4b04-9536-af4da1f71fa0\",\n",
       "    \"name\": \"iris_data_base\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"iris-base-dataset\",\n",
       "    \"workspace\": \"Workspace.create(name='mlops-sanjeev', subscription_id='0d1442c1-d386-4505-9abe-0bedfd63701e', resource_group='mlops')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Registering the dataset\n",
    "dataset =  Dataset.Tabular.from_delimited_files(datastore.path('iris_data_base/iris_data_base.csv'))\n",
    "\n",
    "dataset.register(workspace=ws, name='iris_data_base', description='iris-base-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "307568d1-37f0-4a4c-8b5b-41df80ef0d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_data_base 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0\n",
       "5           5.4          3.9           1.7          0.4        0\n",
       "6           4.6          3.4           1.4          0.3        0\n",
       "7           5.0          3.4           1.5          0.2        0\n",
       "8           4.4          2.9           1.4          0.2        0\n",
       "9           4.9          3.1           1.5          0.1        0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#retrieving the dataset from registered datasets\n",
    "dataset = Dataset.get_by_name(ws, name='iris_data_base')\n",
    "df = dataset.to_pandas_dataframe()\n",
    "print(dataset.name, dataset.version)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e791dcf-ea82-4db9-8b17-8a4c3a0279e5",
   "metadata": {},
   "source": [
    "## Part - II\n",
    "\n",
    "1. Train a Random forest model\n",
    "2. Train a decision tree model\n",
    "3. Register the above models\n",
    "4. Create a scoring file\n",
    "5. Do model profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fee584c-8e7d-4706-b975-da4c03b80db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "x, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y , random_state = 1, test_size = 0.3, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab3952dc-2acb-4593-a1e7-473090789a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def printMetrics(model, test_data, y_labels):\n",
    "    predicted = model.predict(test_data)\n",
    "    acc = accuracy_score(y_labels, predicted)\n",
    "    f1 = f1_score(y_labels, predicted, average = 'macro')\n",
    "    precision = precision_score(y_labels, predicted, average = 'macro')\n",
    "    recall = recall_score(y_labels, predicted, average = 'macro')\n",
    "    print('Accuracy', acc)\n",
    "    print('F1', f1)\n",
    "    print('Precision', precision)\n",
    "    print('Recall', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77396c2f-8d02-40e8-8764-ed2defdf381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree classifier\n",
      "--------------------\n",
      "Params:\n",
      "Criterion gini\n",
      "Max Depth 4\n",
      "--------------------\n",
      "Accuracy 0.9777777777777777\n",
      "F1 0.9777530589543938\n",
      "Precision 0.9791666666666666\n",
      "Recall 0.9777777777777779\n"
     ]
    }
   ],
   "source": [
    "## Searching the best parameters using the GridSearchCV for RFC and DTC\n",
    "\n",
    "# Decision Tree Classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'criterion' : ('gini', 'entropy'), 'max_depth' : [i for i in range(2, 9)]}\n",
    "dt = DecisionTreeClassifier(random_state = 198)\n",
    "grid_ = GridSearchCV(dt, params, n_jobs = -1)\n",
    "grid_.fit(X_train, y_train)\n",
    "dt_best = DecisionTreeClassifier(criterion = grid_.best_params_['criterion'], max_depth = grid_.best_params_['max_depth'], random_state =\n",
    "                                198)\n",
    "dt_best.fit(X_train, y_train)\n",
    "\n",
    "print('Decision Tree classifier')\n",
    "print('-' * 20)\n",
    "print('Params:')\n",
    "print(\"Criterion\", grid_.best_params_['criterion'])\n",
    "print(\"Max Depth\", grid_.best_params_['max_depth'])\n",
    "print('-' * 20)\n",
    "printMetrics(dt_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33d7d9e4-6ccf-4b91-b51e-2a72164055d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier\n",
      "--------------------\n",
      "Params:\n",
      "N estimators 100\n",
      "Max Depth 3\n",
      "--------------------\n",
      "Accuracy 0.9777777777777777\n",
      "F1 0.9777530589543938\n",
      "Precision 0.9791666666666666\n",
      "Recall 0.9777777777777779\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "\n",
    "params = {'n_estimators' : [i for i in range(100, 200, 10)], 'max_depth' : [i for i in range(2, 9)]}\n",
    "\n",
    "rfc = RandomForestClassifier(random_state = 198)\n",
    "grid_ = GridSearchCV(rfc, params, n_jobs = -1)\n",
    "grid_.fit(X_train, y_train)\n",
    "\n",
    "rfc_best = RandomForestClassifier(n_estimators = grid_.best_params_['n_estimators'], max_depth = grid_.best_params_['max_depth'], random_state =\n",
    "                                198)\n",
    "rfc_best.fit(X_train, y_train)\n",
    "\n",
    "print('Random Forest classifier')\n",
    "print('-' * 20)\n",
    "print('Params:')\n",
    "print(\"N estimators\", grid_.best_params_['n_estimators'])\n",
    "print(\"Max Depth\", grid_.best_params_['max_depth'])\n",
    "print('-' * 20)\n",
    "printMetrics(rfc_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68035a8b-f9f5-47fa-9ebc-eee0e6cae96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The maximum opset needed by this model is only 1.\n",
      "The maximum opset needed by this model is only 9.\n",
      "The maximum opset needed by this model is only 1.\n",
      "The maximum opset needed by this model is only 9.\n"
     ]
    }
   ],
   "source": [
    "#Converting the essentials into onnx format\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "initial_type = [('float_input', FloatTensorType([None, 4]))] #4 represents the number of features\n",
    "\n",
    "onx = convert_sklearn(dt_best, initial_types=initial_type)\n",
    "\n",
    "with open(\"./model/iris_dt.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())\n",
    "\n",
    "onx = convert_sklearn(dt_best, initial_types=initial_type)\n",
    "\n",
    "with open(\"./model/iris_rfc.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "804b2384-4b5c-44ff-a2e6-de55561af503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model iris-predictor-rfc\n",
      "Registering model iris-predictor-dt\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_rfc = Model.register(model_path = './model/iris_rfc.onnx', model_name = 'iris-predictor-rfc', tags = {'model_version' : 1},\n",
    "                     description = 'RFC for classifying IRIS', workspace = ws)\n",
    "model_dt = Model.register(model_path = './model/iris_dt.onnx', model_name = 'iris-predictor-dt', tags = {'model_version' : 1},\n",
    "                      description = 'DT for classifying IRIS', workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985d2e7b-35f6-4537-b1fa-f9a16671dcaa",
   "metadata": {},
   "source": [
    "### Testing model - local inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77b3d401-38ae-4c17-b99d-968154e1ac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1], dtype=int64)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 15:36:28.643534800 [W:onnxruntime:, execution_frame.cc:806 VerifyOutputSizes] Expected shape from model of {1} does not match actual shape of {2} for output output_label\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "\n",
    "#iris_predictor = Model(ws, 'iris-predictor', version = 1).download(exist_ok=True) #defaulted under ./models/model_name.onnx\n",
    "\n",
    "sess = rt.InferenceSession(\"./model/iris_rfc.onnx\")\n",
    "\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "\n",
    "test_data = np.array([[5.1, 3.5, 1.4, 0.2], [1.1, 2.8, 4.4, 1.2]])\n",
    "\n",
    "preds = sess.run([label_name], {input_name: test_data.astype(np.float32)})\n",
    "\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84ba145-b45a-4a25-b455-fdb0c70a5e00",
   "metadata": {},
   "source": [
    "## Deploying the model as a local web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f73642e9-7963-4123-bc15-0f08f07210f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"assetId\": \"azureml://locations/centralindia/workspaces/2cdb4132-60a6-427c-8b1a-10c400bf94cb/environments/iris-env/versions/1\",\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"buildContext\": null,\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"iris-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.8.13\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"numpy\",\n",
       "                        \"pandas\",\n",
       "                        \"onnxruntime\",\n",
       "                        \"joblib\",\n",
       "                        \"azureml-core~=1.44.0\",\n",
       "                        \"azureml-monitoring\",\n",
       "                        \"azureml-defaults~=1.44.0\",\n",
       "                        \"Jinja2<3.1\",\n",
       "                        \"scikit-learn==0.22.2.post1\",\n",
       "                        \"inference-schema[numpy-support]\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"project_environment\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Environment\n",
    "\n",
    "env = CondaDependencies.create(pip_packages=[\"numpy\", \"pandas\", \"onnxruntime\", \"joblib\", \"azureml-core\", \"azureml-monitoring\", \"azureml-defaults\", 'Jinja2<3.1', \"scikit-learn==0.22.2.post1\", \"inference-schema\", \"inference-schema[numpy-support]\"])\n",
    "\n",
    "with open('./model/env.yml', 'w') as f:\n",
    "    f.write(env.serialize_to_string())\n",
    "\n",
    "iris_env = Environment.from_conda_specification(name = 'iris-env', file_path = \"./model/env.yml\")\n",
    "    \n",
    "iris_env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a6ed627-3ce7-4669-9aa8-2091666f8e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"./score_v1.py\",\n",
    "                                   environment=iris_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0188c37-9fec-489b-9651-4fc31884523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo service docker start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93b2c5a3-38cb-4bfc-a72d-bdb2c248a427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model iris-predictor-dt:1 to /tmp/azureml_ufdr5ogh/iris-predictor-dt/1\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry 2cdb413260a6427c8b1a10c400bf94cb.azurecr.io\n",
      "Logging into Docker registry 2cdb413260a6427c8b1a10c400bf94cb.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM 2cdb413260a6427c8b1a10c400bf94cb.azurecr.io/azureml/azureml_44403a36f69d445806d69e506c1210a0\n",
      " ---> b649ffae7f00\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 713bc8f27aec\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjBkMTQ0MmMxLWQzODYtNDUwNS05YWJlLTBiZWRmZDYzNzAxZSIsInJlc291cmNlR3JvdXBOYW1lIjoibWxvcHMiLCJhY2NvdW50TmFtZSI6Im1sb3BzLXNhbmplZXYiLCJ3b3Jrc3BhY2VJZCI6IjJjZGI0MTMyLTYwYTYtNDI3Yy04YjFhLTEwYzQwMGJmOTRjYiJ9LCJtb2RlbHMiOnt9LCJtb2RlbHNJbmZvIjp7fX0= | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 2e8614281fbe\n",
      " ---> 1e5243863941\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpfwrd5ndj.py' /var/azureml-app/main.py\n",
      " ---> Running in bc2440538cf0\n",
      " ---> 8d50525be03a\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 17f4a925efc5\n",
      " ---> e10a2fa0cfea\n",
      "Successfully built e10a2fa0cfea\n",
      "Successfully tagged test:latest\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:3da9d604ecd795f1f6828f171bae20dc96e7857e48289f7970a9d825ca22ba7a successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6601\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "\n",
    "model_dt_iris = Model(ws, 'iris-predictor-dt')\n",
    "# This is optional, if not provided Docker will choose a random unused port.\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=6601)\n",
    "\n",
    "local_service = Model.deploy(ws, \"test\", [model_dt_iris], inference_config, deployment_config)\n",
    "\n",
    "local_service.wait_for_deployment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88b3f8e4-2947-4923-9524-795df3bfbbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "#input_data = pd.DataFrame({'sepal.length': [5.1, 1.1], 'sepal.width': [3.5, 2.8], 'petal.length' : [1.4, 4.4], 'petal.width' : [0.2, 1.2]})\n",
    "input_data = {'sepal.length': [5.1, 1.1], 'sepal.width': [3.5, 2.8], 'petal.length' : [1.4, 4.4], 'petal.width' : [0.2, 1.2] }\n",
    "                          #[{'sepal.length': [5.1, 1.1], 'sepal.width': [3.5, 2.8], 'petal.length' : [1.4, 4.4], 'petal.width' : [0.2, 1.2]}]}} #{'data' : {'sepal.length': [5.1, 1.1], 'sepal.width': [3.5, 2.8], 'petal.length' : [1.4, 4.4], 'petal.width' : [0.2, 1.2]] }\n",
    "\n",
    "request = {\"Inputs\": {\"data\" : [[5.1, 3.5, 1.4, 0.2], [1.1, 2.8, 4.4, 1.2] ] }}\n",
    "\n",
    "headers = {'Content-Type': 'application/json', 'Accept': 'text/plain'}\n",
    "\n",
    "scoring_uri = \"http://localhost:6601/score\"\n",
    "resp = requests.post(scoring_uri, json.dumps(request), headers=headers)\n",
    "\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a3ff16-564a-402b-ba68-cac38a8cf9ce",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/72376401/making-predictions-with-azure-machine-learning-with-new-data-that-contains-heade\n",
    "https://stackoverflow.com/questions/64257530/import-data-and-python-scripts-in-azure-ml-entry-script-when-deploying-models\n",
    "https://docs.microsoft.com/en-us/answers/questions/746784/azure-ml-studio-error-while-testing-real-time-endp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f668c4-3510-4f55-85a7-3ee67b30eb0f",
   "metadata": {},
   "source": [
    "## Model profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b90105c6-6b2f-4811-bf76-a66412c98352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading dataset/profile-data/model-profiling-data-v1.txt\n",
      "Uploaded dataset/profile-data/model-profiling-data-v1.txt, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_2952426701534d109f781c0c5face180"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from azureml.core import Datastore\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.data import dataset_type_definitions\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "input_json = {\"Inputs\": {\"data\" : [[5.1, 3.5, 1.4, 0.2], [1.1, 2.8, 4.4, 1.2] ] }}\n",
    "\n",
    "serialized_input_json = json.dumps(input_json)\n",
    "dataset_content = []\n",
    "\n",
    "for i in range(100):\n",
    "     dataset_content.append(serialized_input_json)\n",
    "\n",
    "\n",
    "dataset_content = '\\n'.join(dataset_content)\n",
    "\n",
    "with open('./dataset/profile-data/model-profiling-data-v1.txt', 'w') as f:\n",
    "    f.write(dataset_content)\n",
    "\n",
    "\n",
    "# upload the txt file created above to the Datastore and create a dataset from it\n",
    "datastore = ws.get_default_datastore() # points to the native Azure ML Storage\n",
    "datastore.upload(src_dir = 'dataset/profile-data/', target_path = 'iris_model_profiling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b2fdb5a-d9d2-49e1-9305-7b9719805003",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_request_data = Dataset.Tabular.from_delimited_files(datastore.path('iris_model_profiling/model-profiling-data-v1.txt'), separator='\\n',\n",
    "                                                           infer_column_types=True,\n",
    "                                                          header=dataset_type_definitions.PromoteHeadersBehavior.NO_HEADERS)\n",
    "\n",
    "sample_request_data = sample_request_data.register(workspace=ws, name='iris-profiling-data', create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8407f7a-3024-4fe8-8dda-921e714da000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running..................................................\n",
      "Succeeded\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core import Workspace, Environment\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "iris_env = Environment.get(ws, name = 'iris-env')\n",
    "\n",
    "model = Model(ws, name = 'iris-predictor-dt')\n",
    "inference_config = InferenceConfig(entry_script='score_v1.py',\n",
    "                                   environment = iris_env)\n",
    "\n",
    "input_dataset = Dataset.get_by_name(workspace=ws, name='iris-profiling-data') #dataset should be in the string format hence the above exercise\n",
    "profile = Model.profile(ws,\n",
    "            'iris-model-profile-2',\n",
    "            [model],\n",
    "            inference_config,\n",
    "            input_dataset=input_dataset)\n",
    "\n",
    "profile.wait_for_completion(True)\n",
    "\n",
    "# see the result\n",
    "details = profile.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d88b406d-bffb-4400-aa0e-5c78f995c7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'iris-model-profile-2',\n",
       " 'createdTime': '2022-09-08T16:17:09.527822+00:00',\n",
       " 'state': 'Succeeded',\n",
       " 'requestedCpu': 3.5,\n",
       " 'requestedMemoryInGB': 15.0,\n",
       " 'requestedQueriesPerSecond': 0,\n",
       " 'maxUtilizedMemoryInGB': 0.193830912,\n",
       " 'totalQueries': 100.0,\n",
       " 'successQueries': 100.0,\n",
       " 'successRate': 100.0,\n",
       " 'averageLatencyInMs': 4.7544,\n",
       " 'latencyPercentile50InMs': 3.14,\n",
       " 'latencyPercentile90InMs': 6.4,\n",
       " 'latencyPercentile95InMs': 9.52,\n",
       " 'latencyPercentile99InMs': 41.2,\n",
       " 'latencyPercentile999InMs': 41.2,\n",
       " 'maxUtilizedCpu': 0.022,\n",
       " 'measuredQueriesPerSecond': 210.33148241628805,\n",
       " 'recommendedMemoryInGB': 0.5,\n",
       " 'recommendedCpu': 0.5}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6a6d6-db47-487b-8899-e7a79b1d2a4d",
   "metadata": {},
   "source": [
    "## AKS With Data Drift Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "977aadfc-5d55-4026-9b6e-d30b4a28ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress..........................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "compute_config = AksCompute.provisioning_configuration(location='centralindia', cluster_purpose='DevTest')\n",
    "cluster = ComputeTarget.create(ws, 'iris-aks', compute_config)\n",
    "cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19594d8d-28d0-4baf-a73d-0fae6cbaab1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running......\n",
      "2022-09-08 16:32:24+00:00 Registering the environment.\n",
      "2022-09-08 16:32:26+00:00 Use the existing image for iris-endpoint..\n",
      "2022-09-08 16:35:37+00:00 Creating resources in AKS..\n",
      "2022-09-08 16:35:38+00:00 Submitting deployment to compute.\n",
      "2022-09-08 16:35:38+00:00 Checking the status of deployment iris-endpoint..\n",
      "2022-09-08 16:45:20+00:00 Checking the status of inference endpoint iris-endpoint.\n",
      "Succeeded\n",
      "AKSENDPOINT service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "{\"iris-endpoint\":\"/bin/bash: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n2022-09-08T16:45:08,157556799+00:00 - rsyslog/run \\n2022-09-08T16:45:08,157474898+00:00 - iot-server/run \\n2022-09-08T16:45:08,171893479+00:00 - gunicorn/run \\n2022-09-08T16:45:08,173260796+00:00 | gunicorn/run | \\n2022-09-08T16:45:08,174945317+00:00 | gunicorn/run | ###############################################\\n2022-09-08T16:45:08,176699539+00:00 | gunicorn/run | AzureML Container Runtime Information\\n2022-09-08T16:45:08,178062357+00:00 | gunicorn/run | ###############################################\\n2022-09-08T16:45:08,181119795+00:00 | gunicorn/run | \\n2022-09-08T16:45:08,182675515+00:00 | gunicorn/run | \\nbash: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/libtinfo.so.6: no version information available (required by bash)\\n2022-09-08T16:45:08,201903756+00:00 - nginx/run \\n2022-09-08T16:45:08,224996947+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20220708.v2\\n2022-09-08T16:45:08,226447065+00:00 | gunicorn/run | \\n2022-09-08T16:45:08,227934084+00:00 | gunicorn/run | \\n2022-09-08T16:45:08,229207300+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\n2022-09-08T16:45:08,231022023+00:00 | gunicorn/run | PYTHONPATH environment variable: \\n2022-09-08T16:45:08,232399740+00:00 | gunicorn/run | \\n2022-09-08T16:45:08,233840958+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\\n\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n/bin/bash: /azureml-envs/azureml_1867cd816376033961c66f81bff348cf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\\n2022-09-08T16:45:09,397134190+00:00 - iot-server/finish 1 0\\n2022-09-08T16:45:09,398457207+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nadal==1.2.7\\napplicationinsights==0.11.10\\nargcomplete==2.0.0\\nattrs==22.1.0\\nazure-common==1.1.28\\nazure-core==1.25.1\\nazure-graphrbac==0.61.1\\nazure-identity==1.7.0\\nazure-mgmt-authorization==2.0.0\\nazure-mgmt-containerregistry==10.0.0\\nazure-mgmt-core==1.3.2\\nazure-mgmt-keyvault==10.1.0\\nazure-mgmt-resource==21.1.0\\nazure-mgmt-storage==20.0.0\\nazureml-core==1.44.0\\nazureml-dataprep==4.2.2\\nazureml-dataprep-native==38.0.0\\nazureml-dataprep-rslex==2.8.1\\nazureml-dataset-runtime==1.44.0\\nazureml-defaults==1.44.0\\nazureml-inference-server-http==0.7.5\\nazureml-monitoring==0.1.0a21\\nazureml-telemetry==1.44.0\\nbackports.tempfile==1.0\\nbackports.weakref==1.0.post1\\nbcrypt==4.0.0\\ncachetools==5.2.0\\ncertifi @ file:///opt/conda/conda-bld/certifi_1655968806487/work/certifi\\ncffi==1.15.1\\ncharset-normalizer==2.1.1\\nclick==8.1.3\\ncloudpickle==2.2.0\\ncoloredlogs==15.0.1\\nconfigparser==3.7.4\\ncontextlib2==21.6.0\\ncryptography==37.0.4\\ndistro==1.7.0\\ndocker==5.0.3\\ndotnetcore2==3.1.23\\nFlask==2.1.3\\nFlask-Cors==3.0.10\\nflatbuffers==2.0.7\\nfusepy==3.0.1\\ngoogle-api-core==2.10.0\\ngoogle-auth==2.11.0\\ngoogleapis-common-protos==1.56.4\\ngunicorn==20.1.0\\nhumanfriendly==10.0\\nidna==3.3\\nimportlib-metadata==4.12.0\\nimportlib-resources==5.9.0\\ninference-schema==1.4.2.1\\nisodate==0.6.1\\nitsdangerous==2.1.2\\njeepney==0.8.0\\nJinja2==3.0.3\\njmespath==1.0.0\\njoblib==1.1.0\\njson-logging-py==0.2\\njsonpickle==2.2.0\\njsonschema==4.15.0\\nknack==0.9.0\\nMarkupSafe==2.1.1\\nmpmath==1.2.1\\nmsal==1.18.0\\nmsal-extensions==0.3.1\\nmsrest==0.7.1\\nmsrestazure==0.6.4\\nndg-httpsclient==0.5.1\\nnumpy==1.23.2\\noauthlib==3.2.0\\nonnxruntime==1.12.1\\nopencensus==0.11.0\\nopencensus-context==0.1.3\\nopencensus-ext-azure==1.1.7\\npackaging==21.3\\npandas==1.4.4\\nparamiko==2.11.0\\npathspec==0.10.1\\npkginfo==1.8.3\\npkgutil_resolve_name==1.3.10\\nportalocker==2.5.1\\nprotobuf==4.21.5\\npsutil==5.9.2\\npyarrow==6.0.0\\npyasn1==0.4.8\\npyasn1-modules==0.2.8\\npycparser==2.21\\nPygments==2.13.0\\nPyJWT==2.4.0\\nPyNaCl==1.5.0\\npyOpenSSL==22.0.0\\npyparsing==3.0.9\\npyrsistent==0.18.1\\nPySocks==1.7.1\\npython-dateutil==2.8.2\\npytz==2022.2.1\\nPyYAML==6.0\\nrequests==2.28.1\\nrequests-oauthlib==1.3.1\\nrsa==4.9\\nscikit-learn==0.22.2.post1\\nscipy==1.9.1\\nSecretStorage==3.3.3\\nsix==1.16.0\\nsympy==1.11.1\\ntabulate==0.8.10\\ntyping_extensions==4.3.0\\nurllib3==1.26.9\\nwebsocket-client==1.4.1\\nWerkzeug==2.2.2\\nwrapt==1.12.1\\nzipp==3.8.1\\n\\n2022-09-08T16:45:10,049908601+00:00 | gunicorn/run | \\n2022-09-08T16:45:10,051289919+00:00 | gunicorn/run | ###############################################\\n2022-09-08T16:45:10,052596435+00:00 | gunicorn/run | AzureML Inference Server\\n2022-09-08T16:45:10,053965952+00:00 | gunicorn/run | ###############################################\\n2022-09-08T16:45:10,055377270+00:00 | gunicorn/run | \\n2022-09-08T16:45:10,995779629+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\\n\\nAzure ML Inferencing HTTP server v0.7.5\\n\\n\\nServer Settings\\n---------------\\nEntry Script Name: main.py\\nModel Directory: /var/azureml-app/azureml-models/iris-predictor-dt/1\\nWorker Count: 1\\nWorker Timeout (seconds): 300\\nServer Port: 31311\\nApplication Insights Enabled: false\\nApplication Insights Key: AppInsights key provided\\nInferencing HTTP server version: azmlinfsrv/0.7.5\\nCORS for the specified origins: None\\n\\n\\nServer Routes\\n---------------\\nLiveness Probe: GET   127.0.0.1:31311/\\nScore:          POST  127.0.0.1:31311/score\\n\\nStarting gunicorn 20.1.0\\nListening at: http://0.0.0.0:31311 (15)\\nUsing worker: sync\\nBooting worker with pid: 68\\nInitializing logger\\n2022-09-08 16:45:11,614 | root | INFO | Starting up app insights client\\nlogging socket was found. logging is available.\\nlogging socket was found. logging is available.\\n2022-09-08 16:45:11,614 | root | INFO | Starting up app insight hooks\\n2022-09-08 16:45:12,759 | root | INFO | Found driver script at /var/azureml-app/main.py and the score script at /structure/azureml-app/score_v1.py\\n2022-09-08 16:45:12,759 | root | INFO | run() is decorated with @input_schema. Server will invoke it with the following arguments: Inputs.\\n2022-09-08 16:45:12,759 | root | INFO | Invoking user's init function\\n2022-09-08 16:45:12,763 | root | INFO | Users's init has completed successfully\\n2022-09-08 16:45:12,764 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\\n2022-09-08 16:45:12,764 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\n2022-09-08 16:45:12,765 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\\n2022-09-08 16:45:35,534 | root | INFO | 200\\n127.0.0.1 - - [08/Sep/2022:16:45:35 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 200 2891 \\\"-\\\" \\\"hackney/1.18.1\\\"\\n2022-09-08 16:45:39,679 | root | INFO | 200\\n127.0.0.1 - - [08/Sep/2022:16:45:39 +0000] \\\"GET /swagger.json HTTP/1.0\\\" 200 2891 \\\"-\\\" \\\"hackney/1.18.1\\\"\\n\"}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AksWebservice, Webservice, AksEndpoint\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.compute import AksCompute\n",
    "\n",
    "aks_target = AksCompute(ws, 'iris-aks')\n",
    "model_v1 = Model(ws, 'iris-predictor-dt')\n",
    "\n",
    "# If deploying to a cluster configured for dev/test, ensure that it was created with enough\n",
    "# cores and memory to handle this deployment configuration. Note that memory is also used by\n",
    "# things such as dependencies and AML components.\n",
    "deployment_config = AksEndpoint.deploy_configuration(cpu_cores = 1, memory_gb = 0.5)\n",
    "\n",
    "service = Model.deploy(ws, 'iris-endpoint', [model_v1], inference_config, deployment_config, aks_target)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "\n",
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "caa517ac-3312-4501-bf55-51b8805a4dbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: There is a deployment operation in flight for the Service: iris-endpoint\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"There is a deployment operation in flight for the Service: iris-endpoint\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_v2 \u001b[38;5;241m=\u001b[39m Model(ws, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miris-predictor-dt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mversion-2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_v2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWith RF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraffic_percentile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m service\u001b[38;5;241m.\u001b[39mwait_for_deployment(show_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m service\u001b[38;5;241m.\u001b[39mupdate_version(version_name \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVersion-1\u001b[39m\u001b[38;5;124m'\u001b[39m, is_default \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, traffic_percentile \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m, is_control_version_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/aks.py:1592\u001b[0m, in \u001b[0;36mAksEndpoint.create_version\u001b[0;34m(self, version_name, autoscale_enabled, autoscale_min_replicas, autoscale_max_replicas, autoscale_refresh_seconds, autoscale_target_utilization, collect_model_data, cpu_cores, memory_gb, scoring_timeout_ms, replica_max_concurrent_requests, max_request_wait_time, num_replicas, tags, properties, description, models, inference_config, gpu_cores, period_seconds, initial_delay_seconds, timeout_seconds, success_threshold, failure_threshold, traffic_percentile, is_default, is_control_version_type, cpu_cores_limit, memory_gb_limit)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     version_create_payload[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m AksEndpoint\u001b[38;5;241m.\u001b[39mVersionType\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m   1591\u001b[0m patch_list\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mop\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/versions/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(version_name), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m: version_create_payload})\n\u001b[0;32m-> 1592\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_patch_endpoint_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/aks.py:1856\u001b[0m, in \u001b[0;36mAksEndpoint._patch_endpoint_call\u001b[0;34m(self, headers, params, patch_list)\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_patch_endpoint_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, headers, params, patch_list):\n\u001b[0;32m-> 1856\u001b[0m     \u001b[43mWebservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_for_webservice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mpatch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSERVICE_REQUEST_OPERATION_UPDATE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1858\u001b[0m     resp \u001b[38;5;241m=\u001b[39m ClientBase\u001b[38;5;241m.\u001b[39m_execute_func(get_requests_session()\u001b[38;5;241m.\u001b[39mpatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mms_endpoint, headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1859\u001b[0m                                     params\u001b[38;5;241m=\u001b[39mparams, json\u001b[38;5;241m=\u001b[39mpatch_list)\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/webservice.py:744\u001b[0m, in \u001b[0;36mWebservice._check_for_webservice\u001b[0;34m(workspace, name, compute_type, payload, action, request_func, check_func)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_func\u001b[39m(content):\n\u001b[1;32m    742\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Webservice\u001b[38;5;241m.\u001b[39m_check_validate_error(content)\n\u001b[0;32m--> 744\u001b[0m \u001b[43mWebservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_validate_framework\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/webservice.py:638\u001b[0m, in \u001b[0;36mWebservice._run_validate_framework\u001b[0;34m(request_func, check_func)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error:\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m WebserviceException(error)\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: There is a deployment operation in flight for the Service: iris-endpoint\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"There is a deployment operation in flight for the Service: iris-endpoint\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "model_v2 = Model(ws, 'iris-predictor-dt')\n",
    "service.create_version( version_name= 'version-2', inference_config=inference_config, models=[model_v2], description=\"With RF\", traffic_percentile=50)\n",
    "service.wait_for_deployment(show_output=True)\n",
    "service.update_version(version_name =  'Version-1', is_default = True, traffic_percentile = 50, is_control_version_type = True)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b4c76fd-27c7-49ac-9abc-6901646abc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "test_sample = json.dumps({\"Inputs\": {\"data\" : [[5.1, 3.5, 1.4, 0.2], [1.1, 2.8, 4.4, 1.2] ] }})\n",
    "\n",
    "test_sample_encoded = bytes(test_sample, encoding='utf8')\n",
    "prediction = service.run(input_data=test_sample_encoded)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e3c9f-91d6-4ed0-9372-f0951e95949a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
